{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KiPmRubtWbm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from xgboost import XGBRegressor\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/cleaned_dataset.csv')"
      ],
      "metadata": {
        "id": "5nHA-9yowpN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "l-lPon_uwuWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing X and Y columns"
      ],
      "metadata": {
        "id": "4CR_4DBKwyu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=['Exam_Score'])"
      ],
      "metadata": {
        "id": "-B2BId8Rwv6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "id": "rMgccIRtw9SV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['Exam_Score']"
      ],
      "metadata": {
        "id": "gW5maWsaw-UR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "s2TV64JMxBdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "scaler = RobustScaler()\n",
        "robust_scaled = scaler.fit_transform(X)\n",
        "robust_scaled_df = pd.DataFrame(robust_scaled, columns=X.columns)"
      ],
      "metadata": {
        "id": "xESXus9uxDE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test =train_test_split(robust_scaled_df, y, test_size =0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "k66uXRJQMEgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train model\n",
        "model = LinearRegression()\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_train_pred = model.predict(x_train)\n",
        "y_test_pred = model.predict(x_test)\n",
        "\n",
        "# Evaluation metrics\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "mae = mean_absolute_error(y_test, y_test_pred)\n",
        "mse = mean_squared_error(y_test, y_test_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "print(test_r2)\n",
        "print(train_r2)"
      ],
      "metadata": {
        "id": "ucFgSCBgMIGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "tRz8V3zYx5YJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
        "# X_train.shape, X_test.shape"
      ],
      "metadata": {
        "id": "yqA4hyOx2Lt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate Function to give all metrics after Model Training"
      ],
      "metadata": {
        "id": "N-akA6K_8MeR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(true, predicted):\n",
        "  mae = mean_absolute_error(true, predicted)\n",
        "  mse = mean_squared_error(true, predicted)\n",
        "  rmse = np.sqrt(mean_squared_error(true, predicted))\n",
        "  r2_square = r2_score(true, predicted)\n",
        "  return mae, rmse, r2_square"
      ],
      "metadata": {
        "id": "eRg3i2jP2pDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "models = {\n",
        "    \"Linear Regression\": LinearRegression(),\n",
        "    \"Lasso\": Lasso(),\n",
        "    \"Ridge\": Ridge(),\n",
        "    \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
        "    \"Decision Tree\": DecisionTreeRegressor(),\n",
        "    \"Random Forest Regressor\": RandomForestRegressor(),\n",
        "    \"XGBRegressor\": XGBRegressor(),\n",
        "    \"AdaBoost Regressor\": AdaBoostRegressor()\n",
        "}\n",
        "\n",
        "model_list = []\n",
        "r2_list = []\n",
        "\n",
        "for i in range(len(list(models))):\n",
        "  model = list(models.values())[i]\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  y_train_pred = model.predict(X_train)\n",
        "  y_test_pred = model.predict(X_test)\n",
        "\n",
        "  model_train_mae, model_train_rmse, model_train_r2 = evaluate_model(y_train, y_train_pred)\n",
        "  model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
        "\n",
        "  print(list(models.keys())[i])\n",
        "  model_list.append(list(models.keys())[i])\n",
        "  print('Model performance for Training set')\n",
        "  print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
        "  print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
        "  print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
        "\n",
        "  print('----------------------------------')\n",
        "\n",
        "  print('Model performance for Test set')\n",
        "  print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
        "  print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
        "  print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
        "  r2_list.append(model_test_r2)\n",
        "\n",
        "  print('='*35)\n",
        "  print('\\n')\n"
      ],
      "metadata": {
        "id": "reWV-fzK8v4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(list(zip(model_list, r2_list)), columns=['Model Name', 'R2_Score']).sort_values(by=[\"R2_Score\"],ascending=False)"
      ],
      "metadata": {
        "id": "6u9DpFva96QN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Define Polynomial Regression model (degree=2)\n",
        "poly_reg = Pipeline([\n",
        "    (\"poly_features\", PolynomialFeatures(degree=2, include_bias=False)),\n",
        "    (\"linear_regression\", LinearRegression())\n",
        "])\n",
        "\n",
        "# Fit on training set\n",
        "poly_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_train_pred = poly_reg.predict(X_train)\n",
        "y_test_pred = poly_reg.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "model_train_mae, model_train_rmse, model_train_r2 = evaluate_model(y_train, y_train_pred)\n",
        "model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
        "\n",
        "print(\"Polynomial Regression (deg=2)\")\n",
        "print('Model performance for Training set')\n",
        "print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
        "print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
        "print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
        "\n",
        "print('----------------------------------')\n",
        "\n",
        "print('Model performance for Test set')\n",
        "print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
        "print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
        "print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n"
      ],
      "metadata": {
        "id": "POTY9FLaJP3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Dataset is linear in nature, Regression dominates\n",
        "- Tree ensembles perform better\n",
        "- Boosting methods crashed as they are not suitable without tuning\n",
        "- KNN struggles due to dimensionality and scaling"
      ],
      "metadata": {
        "id": "mpz3yQ2VKBJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter Plot: Actual vs Predicted\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.scatterplot(x=y_test, y=y_test_pred, color='#ff4252', alpha=0.3)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='#0d3b66', linestyle='--')\n",
        "plt.xlabel(\"Actual Exam Score\")\n",
        "plt.ylabel(\"Predicted Exam Score\")\n",
        "plt.title(\"Actual vs Predicted Exam Scores\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mNFnGTvOJWSp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}